{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa07d82-0ac4-4911-9a7a-5810aad6d621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "#import cartopy.crs as ccrs\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "from __future__ import division\n",
    "import os\n",
    "import shutil\n",
    "from subprocess import call\n",
    "import itertools\n",
    "import fnmatch\n",
    "from calendar import monthrange\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "### automatically refresh the buffer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### solve the auto-complete issue\n",
    "\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "### lvl 1 setups\n",
    "\n",
    "import sys\n",
    "sys.path.append('/portal1/dell/GitHub/WAYS')\n",
    "sys.path.append('/portal1/dell/GitHub/sanctuary')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "### lvl 2 setups (systerm)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from numpy import hstack\n",
    "from matplotlib import pyplot\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import polyfit, poly1d\n",
    "from stats import cr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from stats import cr\n",
    "from gistool import basemap, stack_image, stack_shp, stack_hatch, stack_shp_cn, ncslice\n",
    "from spatial import upscale\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats.mstats import theilslopes\n",
    "from scipy.stats import kendalltau\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import climate_indices as indices\n",
    "from climate_indices import compute\n",
    "from climate_indices import utils, indices\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305af720-e54c-45b2-9055-29777b381e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for k in range(1960,1965):  ######\n",
    "    df = pd.read_csv('fd_wet_traj/lag+1/lag+1_'+str(k)+'.csv') ########\n",
    "    \n",
    "    df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='geometry')\n",
    "    lonn = gdf.geometry.x.values\n",
    "    latt = gdf.geometry.y.values\n",
    "    sph = gdf['Specific_Humidity'].values\n",
    "    traj_loc_sp = np.stack((gdf.geometry.x.values, gdf.geometry.y.values, gdf['Specific_Humidity'].values), axis=-1)\n",
    "    last_traj_number = df['traj'].iloc[-1][4:]\n",
    "\n",
    "\n",
    "    domain_n = np.zeros((361,721))\n",
    "    domain_m = np.zeros((361,721))\n",
    "    lat_largescale= list(np.linspace(90,-90,361))\n",
    "    lon_largescale= list(np.linspace(-180,180,721))\n",
    "    pscf_domain_n= xr.DataArray(domain_n, coords=[lat_largescale, lon_largescale], dims=['lat','lon']) \n",
    "    pscf_domain_m= xr.DataArray(domain_m, coords=[lat_largescale, lon_largescale], dims=['lat','lon'])\n",
    "    \n",
    "    \n",
    "    print(str(k)+\"begin:\", datetime.now())\n",
    "    \n",
    "    last_traj_number = df['traj'].iloc[-1][4:]   # how much traj you have   int(last_traj_number) int(last_traj_number)\n",
    "    for i in range(int(last_traj_number)):\n",
    "        \n",
    "        traj_indexes = df[df['traj'] == 'traj'+str(i)].index\n",
    "        for j in range(traj_indexes[0], traj_indexes[-1]):  # how much traj point in specific traj\n",
    "            \n",
    "            pscf_loc_n=pscf_domain_n.sel(lat=traj_loc_sp[j][1],lon=traj_loc_sp[j][0],method='nearest')\n",
    "            lat_pscf_n=lat_largescale.index(pscf_loc_n.lat.values)\n",
    "            lon_pscf_n=lon_largescale.index(pscf_loc_n.lon.values)\n",
    "            domain_n[lat_pscf_n][lon_pscf_n]=domain_n[lat_pscf_n][lon_pscf_n]+1\n",
    "            \n",
    "            \n",
    "            # calculate how much the traj point in specific grid of (last_traj -> path_traj) \n",
    "            if traj_loc_sp[j][2] > traj_loc_sp[traj_indexes[0]][2]:\n",
    "                pscf_loc_m=pscf_domain_m.sel(lat=traj_loc_sp[j][1],lon=traj_loc_sp[j][0],method='nearest')\n",
    "                lat_pscf_m=lat_largescale.index(pscf_loc_m.lat.values)\n",
    "                lon_pscf_m=lon_largescale.index(pscf_loc_m.lon.values)\n",
    "                domain_m[lat_pscf_m][lon_pscf_m]=domain_m[lat_pscf_m][lon_pscf_m]+1\n",
    "        if i%5000 == 0:\n",
    "            print(str(k)+\"__\"+str(i), datetime.now())\n",
    "    \n",
    "    print(str(k)+\"end:\", datetime.now())\n",
    "    \n",
    "    pscf_sustech = domain_m/domain_n\n",
    "    ds_domain_m = xr.Dataset({'domain_m': (['time', 'lat', 'lon'], domain_m.reshape(1,361,721))},\n",
    "                    coords={'lon': (['lon'], lon_largescale),\n",
    "                            'lat': (['lat'], lat_largescale),\n",
    "                            'time': (['time'], [k]),})\n",
    "    ds_domain_m.to_netcdf('pscf_wet/lag+1/domain_m_'+str(k)+'.nc')       #######\n",
    "\n",
    "    ds_domain_n = xr.Dataset({'domain_n': (['time', 'lat', 'lon'], domain_n.reshape(1,361,721))},\n",
    "                    coords={'lon': (['lon'], lon_largescale),\n",
    "                            'lat': (['lat'], lat_largescale),\n",
    "                            'time': (['time'], [k]),})\n",
    "    ds_domain_n.to_netcdf('pscf_wet/lag+1/domain_n_'+str(k)+'.nc')      #######\n",
    "    ds_pscf_sustech = xr.Dataset({'pscf': (['time', 'lat', 'lon'], pscf_sustech.reshape(1,361,721))},\n",
    "                    coords={'lon': (['lon'], lon_largescale),\n",
    "                            'lat': (['lat'], lat_largescale),\n",
    "                            'time': (['time'], [k]),})\n",
    "    \n",
    "    ds_pscf_sustech.to_netcdf('pscf_wet/lag+1/pscf_'+str(k)+'.nc')    #######\n",
    "    \n",
    "    condition_1 = domain_n > 3*np.nanmean(domain_n) \n",
    "    condition_2 = (1.5*np.nanmean(domain_n)  < domain_n) & (domain_n <= 3*np.nanmean(domain_n) )\n",
    "    condition_3 = (np.nanmean(domain_n)  < domain_n) & (domain_n <= 1.5*np.nanmean(domain_n) )\n",
    "    condition_4 = domain_n <= np.nanmean(domain_n) \n",
    "    \n",
    "    pscf_sustech[condition_1] *= 1.0\n",
    "    pscf_sustech[condition_2] *= 0.7\n",
    "    pscf_sustech[condition_3] *= 0.4\n",
    "    pscf_sustech[condition_4] *= 0.2\n",
    "\n",
    "    ds_wpscf_sustech = xr.Dataset({'wpscf': (['time', 'lat', 'lon'], pscf_sustech.reshape(1,361,721))},\n",
    "                    coords={'lon': (['lon'], lon_largescale),\n",
    "                            'lat': (['lat'], lat_largescale),\n",
    "                            'time': (['time'], [k]),})\n",
    "    ds_wpscf_sustech.to_netcdf('pscf_wet/lag+1/wpscf_'+str(k)+'.nc')      #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba69d916-afff-4587-92f0-f921a81fb7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
